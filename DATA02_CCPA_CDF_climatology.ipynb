{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1049bf1f-5f77-47d5-9fea-50f2676a706e",
   "metadata": {},
   "source": [
    "# CCPA CDF estimation\n",
    "\n",
    "* This notebook produces CCPA CDFs on each grid cell and forecast lead time from 2002 to 2019.\n",
    "* The CDF is used as climatology reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94d78bc5-9d18-43df-b57e-dfb5c05b96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21fbec6e-34ee-48aa-be45-32bd5278e7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6558f236-d803-4e0b-977b-85ed6b78294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f498a4f-56fe-4f34-92d6-b75d9772a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(save_dir+'CCPA_domain.hdf', 'r') as h5io:\n",
    "    lon_CCPA = h5io['lon_CCPA'][...]\n",
    "    lat_CCPA = h5io['lat_CCPA'][...]\n",
    "    land_mask_CCPA = h5io['land_mask_CCPA'][...]\n",
    "\n",
    "land_mask_ = land_mask_CCPA == 1.0\n",
    "grid_shape = land_mask_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b943c65-c311-497a-8290-ee8ab7c6763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_bins = np.array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
    "                   0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
    "                   0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
    "                   0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
    "                   0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
    "                   0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
    "                   0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
    "                   0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
    "                   0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, \n",
    "                   0.99, 0.991, 0.992, 0.993, 0.994, 0.995, 0.996, 0.997, 0.998, 0.999])\n",
    "\n",
    "N_bins = len(q_bins) + 1 # add max value in the end\n",
    "YEARs = np.arange(2002, 2020, 1)\n",
    "HOURs = np.arange(0, 24, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b1619-d522-4a1c-b7b5-e335dd925c08",
   "metadata": {},
   "source": [
    "## Compute CDFs on individual locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1924bba1-4e66-4a27-b483-030f08aea33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base = datetime(2002, 1, 1)\n",
    "# date_list = [base + timedelta(days=day) for day in range(365*18+4)]\n",
    "\n",
    "# CCPA_name = camp_dir+'CCPA/CCPA_y{}.hdf'\n",
    "# CCPA_collect = np.empty((len(date_list), len(HOURs)))\n",
    "# quantile_save = camp_dir+'CCPA/CCPA_qbin_2002_2019_ix{:03d}_iy{:03d}_h{:02d}.npy'\n",
    "# q_ccpa_save = np.empty((N_bins,))\n",
    "\n",
    "# for ix in range(grid_shape[0]):\n",
    "#     for iy in range(grid_shape[1]):\n",
    "        \n",
    "#         # if it is a land grid point\n",
    "#         if land_mask_[ix, iy]:\n",
    "            \n",
    "#             # check if this location has been done by previous runs\n",
    "#             flag_not_exist = False\n",
    "#             for i_hour, hour in enumerate(HOURs):\n",
    "#                 name_ = quantile_save.format(ix, iy, hour)\n",
    "#                 if os.path.isfile(name_) is False:\n",
    "#                     flag_not_exist = True\n",
    "                    \n",
    "#             # if at least one of the hours is missing --> start\n",
    "#             if flag_not_exist:\n",
    "#                 print('working on ix={}, iy={}'.format(ix, iy))\n",
    "#                 # collect all available CCPA values\n",
    "#                 count = 0\n",
    "#                 for i_year, year in enumerate(YEARs):\n",
    "#                     with h5py.File(CCPA_name.format(year), 'r') as h5io:\n",
    "#                         ccpa_temp = h5io['CCPA'][..., ix, iy]\n",
    "#                     L_temp = len(ccpa_temp)\n",
    "#                     CCPA_collect[count:count+L_temp, :] = ccpa_temp\n",
    "#                     count += L_temp\n",
    "    \n",
    "#                 for i_hour, hour in enumerate(HOURs):\n",
    "#                     # clear old values to be safe\n",
    "#                     q_ccpa_save[...] = np.nan\n",
    "                    \n",
    "#                     # get non-NaN value collections\n",
    "#                     ccpa_hour = CCPA_collect[:, i_hour]\n",
    "#                     ccpa_hour = ccpa_hour[~np.isnan(ccpa_hour)]\n",
    "\n",
    "#                     # estimate the quantile\n",
    "#                     q_ccpa_save[:-1] = np.quantile(ccpa_hour, q_bins)\n",
    "#                     q_ccpa_save[-1] = np.max(ccpa_hour)\n",
    "#                     name_ = quantile_save.format(ix, iy, hour)\n",
    "#                     print(name_)\n",
    "#                     np.save(name_, q_ccpa)\n",
    "\n",
    "#             raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfd327b-5c43-4e20-bd5f-dc051cc37046",
   "metadata": {},
   "source": [
    "## Merge individual location CDFs to a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49352973-08a1-4d47-afe6-79bb324ebf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CDFs = np.empty((N_bins,)+grid_shape+(4,))\n",
    "CDFs[...] = np.nan\n",
    "\n",
    "filenames = camp_dir+'CCPA/CCPA_qbin_2002_2019_ix{:03d}_iy{:03d}_h{:02d}.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65ff2705-a56e-47e2-aaa9-762c701e6136",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(grid_shape[0]):\n",
    "    for iy in range(grid_shape[1]):\n",
    "        if land_mask_[ix, iy]:\n",
    "            for i_hour, hour in enumerate(HOURs):\n",
    "                name_ = filenamess.format(ix, iy, hour)\n",
    "                if os.path.isfile(name_):\n",
    "                    CDFs[:, ix, iy, i_hour] = np.load(name_)\n",
    "                else:\n",
    "                    print('Missing {}'.format(name_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdff9c32-f1d0-497b-bebf-f8b991a4b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuple_save = (CDFs,)\n",
    "# label_save = ['CCPA_CDFs',]\n",
    "# du.save_hdf5(tuple_save, label_save, camp_dir+'CCPA/', 'CCPA_CDFs_2002_2019.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d1de3-6bf4-4f7a-b920-2e41bf49fd24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
