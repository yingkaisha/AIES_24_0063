{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9e0abe-22a0-452a-b47b-049921603459",
   "metadata": {},
   "source": [
    "# A summary of all models\n",
    "\n",
    "This notebook summarizes all the neural network components of this research\n",
    "\n",
    "* VQ-VAE\n",
    "* ViT-based bias correction model\n",
    "* Latent Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faff0e75-1225-4abe-b3c3-50afe7354c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# ------------------------------------------------------- #\n",
    "# Turn-off warnings\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# ------------------------------------------------------- #\n",
    "# Turn-off tensoflow-specific warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# ------------------------------------------------------- #\n",
    "# Import customized modules and settings\n",
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "import model_utils as mu\n",
    "import verif_utils as vu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa66857-b9f6-46c2-ab6a-a447e333f9cd",
   "metadata": {},
   "source": [
    "## VQ-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe784d15-75e5-4bbe-b48e-d4ce830b8254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "filter_nums = [64, 128] # number of convolution kernels per down-/upsampling layer \n",
    "latent_dim = 4 # number of latent feature channels\n",
    "activation = 'gelu' # activation function\n",
    "num_embeddings = 128 #128 # number of the VQ codes\n",
    "\n",
    "input_size = (224, 464, 1) # size of MRMS input\n",
    "latent_size = (14, 29, latent_dim) # size of compressed latent features\n",
    "\n",
    "drop_encode = True\n",
    "drop_decode = True\n",
    "\n",
    "model_name_encoder_load = model_dir+'models/VQ_VAE_encoder_stack1_tune0'\n",
    "model_name_decoder_load = model_dir+'models/VQ_VAE_decoder_stack1_tune0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c484720-749c-42c3-b6ba-d7dacd23f60a",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "614660e7-d4bf-4004-82f1-af9100e21312",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = mu.VQ_VAE_encoder_x4(input_size, filter_nums, latent_dim, num_embeddings, activation, drop_encode)\n",
    "\n",
    "W_old = mu.dummy_loader(model_name_encoder_load)\n",
    "encoder.set_weights(W_old)\n",
    "\n",
    "decoder = mu.VQ_VAE_decoder_x4(latent_size, filter_nums, activation, drop_decode)\n",
    "\n",
    "W_old = mu.dummy_loader(model_name_decoder_load)\n",
    "decoder.set_weights(W_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e1523d7-6940-497a-8957-3a6a210815f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the encoder and decoder\n",
    "X = keras.Input(shape=input_size)\n",
    "X_encode = encoder(X)\n",
    "X_decode = decoder(X_encode)\n",
    "VQ_VAE = keras.Model(X, X_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b2bab-1cb9-4d9c-b6bf-2da57ab2e448",
   "metadata": {},
   "source": [
    "### Try on the validations set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75cb3d0f-ec95-4b2a-b48a-6d64815d84b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_dir = camp_dir+'BATCH_CCPA_full/'\n",
    "# validation set size\n",
    "\n",
    "# collect validation set sampales\n",
    "filenames = sorted(glob(BATCH_dir+'*.npy'))\n",
    "filenames = filenames[:-3648]\n",
    "L = len(filenames)\n",
    "\n",
    "#filename_valid = filenames[::8][:2627]\n",
    "filename_valid = filenames[::8][:500] # samller validation set size\n",
    "L_valid = len(filename_valid)\n",
    "\n",
    "Y_valid = np.empty((L_valid, 224, 464, 1))\n",
    "Y_valid[...] = np.nan\n",
    "\n",
    "for i, name in enumerate(filename_valid):\n",
    "    Y_valid[i, ..., 0] = np.load(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1aba5efd-ba8c-4cb4-9be9-2b551abc5ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 7s 314ms/step\n",
      "MAE: 0.0054497166918077156\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "Y_pred = VQ_VAE.predict(Y_valid)\n",
    "Y_pred[Y_pred<0] = 0\n",
    "record = du.mean_absolute_error(Y_valid, Y_pred)\n",
    "print('MAE: {}'.format(record))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b8935b-51be-42fa-b77a-ded47766d542",
   "metadata": {},
   "source": [
    "## Bias-correction ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "402e328d-a513-4055-8dbd-1b316701300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tensor size of embedded CCPA and GEFS ensemble mean \n",
    "latent_size = (14, 29, 4)\n",
    "# input size for the 48h models\n",
    "input_size = (8,) + latent_size\n",
    "\n",
    "# patch size\n",
    "patch_size = (1, 1, 1) # (time, space, space)\n",
    "\n",
    "N_heads = 4\n",
    "N_layers = 8\n",
    "project_dim = 128\n",
    "\n",
    "model_name_load_48h = model_dir+'baseline/ViT3d_0_48_depth{}_patch{}{}{}_dim{}_heads{}_tune'.format(\n",
    "    N_layers, patch_size[0], patch_size[1], patch_size[2], project_dim, N_heads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a514f-ee40-478a-b17a-e9b8dfde432a",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fb68d40-e48e-4ef7-849a-cb162cb6dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_48h = mu.ViT3d_corrector(input_size, patch_size, project_dim, N_layers, N_heads)\n",
    "\n",
    "W_old = mu.dummy_loader(model_name_load_48h)\n",
    "model_48h.set_weights(W_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ee0f89-b68b-4ae7-a1b1-0820c8882e2d",
   "metadata": {},
   "source": [
    "### Try on the validations set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c759d0ae-0a09-442e-8847-ddfbc2f62f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_dir = camp_dir+'BATCH_ViT/'\n",
    "filenames = sorted(glob(BATCH_dir+'*npy'))\n",
    "\n",
    "L_valid = 500\n",
    "filenames_valid = filenames[:L_valid]\n",
    "\n",
    "valid_GEFS = np.empty((L_valid, 8,)+latent_size)\n",
    "valid_CCPA = np.empty((L_valid, 8,)+latent_size)\n",
    "\n",
    "for i, name_ in enumerate(filenames_valid):\n",
    "    temp_data = np.load(name_, allow_pickle=True)[()]\n",
    "    valid_GEFS[i, ...] = temp_data['GEFS_embed'][:8, ...]\n",
    "    valid_CCPA[i, ...] = temp_data['CCPA_embed'][:8, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57cbf057-aa48-4d15-86ff-6e9b36e35c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 12s 667ms/step\n",
      "0.03936765624405502\n"
     ]
    }
   ],
   "source": [
    "Y_pred_48 = model_48h.predict(valid_GEFS[:, 0:8, ...])\n",
    "record = du.mean_absolute_error(valid_CCPA[:, 0:8, ...], Y_pred_48)\n",
    "print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad33f5e-d715-49f3-985e-4af7306b7c80",
   "metadata": {},
   "source": [
    "## Diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f73ce57-6995-4a73-bc54-05991b22b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tensor size of embedded CCPA and GEFS ensemble mean \n",
    "latent_size = (14, 29, 4)\n",
    "input_size = (24,) + latent_size # LDM generates all 06-144, (24,) lead times\n",
    "\n",
    "# model design\n",
    "widths = [32, 64, 96, 128]\n",
    "embedding_dims = 32\n",
    "block_depth = 2\n",
    "\n",
    "# diffusion steps\n",
    "diffusion_steps = 20\n",
    "min_signal_rate = 0.02\n",
    "max_signal_rate = 0.95\n",
    "ema = 0.999\n",
    "\n",
    "# location of the previous weights\n",
    "model_name_load = model_dir+'models/LDM_3d_tune4/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67a9791-d092-4130-b9b3-6c8c1e1726dc",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0400ff9c-1b7e-4667-a008-c07f15d4ffe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x1526e5c7c9d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDM = mu.DiffusionModel(input_size, input_size, input_size, \n",
    "                        diffusion_steps, min_signal_rate, max_signal_rate, \n",
    "                        embedding_dims, widths, block_depth, ema)\n",
    "\n",
    "LDM.load_weights(model_name_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0787d009-3849-4191-afc7-e2c715a1bd9a",
   "metadata": {},
   "source": [
    "### Try on the validations set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fb1b234-4804-4965-9928-aaf87e7f4eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max values\n",
    "ccpa_min = -2.0606\n",
    "ccpa_max = 1.6031\n",
    "\n",
    "# Rescale to [-1, 1]\n",
    "def rescale(x, min_val=ccpa_min, max_val=ccpa_max):\n",
    "    return ((x - min_val) / (max_val - min_val))* 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65331c3f-121b-4df4-b2d1-7e75ac4b48e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_dir = camp_dir+'BATCH_LDM/'\n",
    "filenames = sorted(glob(BATCH_dir+'*npy'))\n",
    "\n",
    "L_valid = 100\n",
    "filenames_valid = filenames[::40][:L_valid]\n",
    "\n",
    "valid_CCPA = np.empty((L_valid, input_size[0],)+latent_size)\n",
    "valid_ViT = np.empty((L_valid, input_size[0],)+latent_size)\n",
    "\n",
    "for i, name_ in enumerate(filenames_valid):\n",
    "    temp_data = np.load(name_, allow_pickle=True)[()]\n",
    "    valid_CCPA[i, ...] = temp_data['CCPA_embed'][:input_size[0], ...]\n",
    "    valid_ViT[i, ...] = temp_data['ViT_embed'][:input_size[0], ...]\n",
    "\n",
    "valid_CCPA = rescale(valid_CCPA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c878bf3-2e84-4c83-bb92-fd2f9c5af944",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ViT = rescale(valid_ViT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "158248e3-40b1-448a-b957-81b0ab5db3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028370507129221484\n"
     ]
    }
   ],
   "source": [
    "y_pred = LDM.generate(L_valid, valid_ViT)\n",
    "y_pred = np.array(y_pred)\n",
    "record = du.mean_absolute_error(y_pred, valid_CCPA)\n",
    "print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b214f-1283-4c70-a49d-2ed75f68dc42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
