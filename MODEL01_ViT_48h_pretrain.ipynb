{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de92920-99ef-48bb-b6db-54df00ae5796",
   "metadata": {},
   "source": [
    "# 3D ViT for the Bias-correction of GEFS ensemble mean\n",
    "\n",
    "This notebook contains information for the design, hyperparameters, and pre-training of a 3D ViT that corrects the conditional bias of GEFS ensemble mean within the VQ-VAE latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a9dfa9-e564-444d-84d4-d0c3212bb61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# ------------------------------------------------------- #\n",
    "# Turn-off warnings\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# ------------------------------------------------------- #\n",
    "# Turn-off tensoflow-specific warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# ------------------------------------------------------- #\n",
    "# Import customized modules and settings\n",
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/')\n",
    "sys.path.insert(0, '/glade/u/home/ksha/GAN_proj/libs/')\n",
    "\n",
    "from namelist import *\n",
    "import data_utils as du\n",
    "import model_utils as mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c66595-cd34-4abe-a459-57c5eb1caff4",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cb6a0bf-d943-4a52-b6c2-fba3b78a9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------- #\n",
    "# Hyperparameters\n",
    "# input size for the 48h models\n",
    "latent_size = (14, 29, 4)\n",
    "input_size = (8,) + latent_size\n",
    "\n",
    "# 0-48 hr settings\n",
    "lead_name = '0_48'\n",
    "ilead_start = 0\n",
    "ilead_end = 8\n",
    "N_leads = ilead_end - ilead_start\n",
    "\n",
    "# # 54-96 hr settings\n",
    "# lead_name = '54_96'\n",
    "# ilead_start = 8\n",
    "# ilead_end = 16\n",
    "# N_leads = ilead_end - ilead_start\n",
    "\n",
    "# # 102-144 hr settings\n",
    "# lead_name = '102_144'\n",
    "# ilead_start = 16\n",
    "# ilead_end = 24\n",
    "# N_leads = ilead_end - ilead_start\n",
    "\n",
    "# ============================= #\n",
    "# Tuned hyperparameters\n",
    "patch_size = (1, 1, 1) # (time, space, space)\n",
    "N_heads = 4\n",
    "N_layers = 8\n",
    "project_dim = 128\n",
    "# ============================= #\n",
    "\n",
    "load_weights = True\n",
    "\n",
    "# location of the previous weights\n",
    "model_name_load = model_dir+'models/ViT3d_{}_depth{}_patch{}{}{}_dim{}_heads{}_tune'.format(\n",
    "    lead_name, N_layers, patch_size[0], patch_size[1], patch_size[2], project_dim, N_heads)\n",
    "# location for saving new weights\n",
    "model_name_save = model_dir+'models/ViT3d_{}_depth{}_patch{}{}{}_dim{}_heads{}_tune'.format(\n",
    "    lead_name, N_layers, patch_size[0], patch_size[1], patch_size[2], project_dim, N_heads)\n",
    "\n",
    "# Training setups\n",
    "lr = 1e-4\n",
    "batch_size = 4 #64\n",
    "N_batch = 32\n",
    "epochs = 9999\n",
    "\n",
    "aug_timelag = True\n",
    "aug_revert = True\n",
    "\n",
    "if aug_timelag:\n",
    "    pad_timelag = 2\n",
    "else:\n",
    "    pad_timelag = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b880aa-c679-4d41-aaa8-844514be8b3f",
   "metadata": {},
   "source": [
    "## Validation set prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5e77dcd-79d5-45c5-b374-76b3831a3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------- #\n",
    "# Validation set\n",
    "# BATCH_dir = camp_dir+'BATCH_ViT_OPT/'\n",
    "BATCH_dir = camp_dir='BATCH_ViT/'\n",
    "filenames = sorted(glob(BATCH_dir+'*npy'))\n",
    "\n",
    "L_valid = 500\n",
    "filenames_valid = filenames[::10][:L_valid]\n",
    "\n",
    "valid_GEFS = np.empty((L_valid, N_leads,)+latent_size)\n",
    "valid_CCPA = np.empty((L_valid, N_leads,)+latent_size)\n",
    "\n",
    "for i, name_ in enumerate(filenames_valid):\n",
    "    temp_data = np.load(name_, allow_pickle=True)[()]\n",
    "    valid_GEFS[i, ...] = temp_data['GEFS_embed'][ilead_start:ilead_end, ...]\n",
    "    valid_CCPA[i, ...] = temp_data['CCPA_embed'][ilead_start:ilead_end, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde420f0-e4fc-429a-b92d-0c346875fc48",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca6d179-7373-493b-8e88-641235b9ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_dir = camp_dir+'BATCH_ViT/'\n",
    "filename_train = sorted(glob(BATCH_dir+'*npy'))\n",
    "filename_train = list(set(filename_train) - set(filenames_valid))\n",
    "L_train = len(filename_train)\n",
    "\n",
    "min_del = 0.0\n",
    "max_tol = 3 # early stopping with 2-epoch patience\n",
    "tol = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bae1181-f376-4a10-a870-af272b168af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n",
      "epoch = 0\n",
      "16/16 [==============================] - 12s 667ms/step\n",
      "Initial validation loss: 0.04268202272848104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------- #\n",
    "# Training loop\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    \n",
    "    model = mu.ViT3d_corrector(input_size, patch_size, project_dim, N_layers, N_heads)\n",
    "    model.compile(loss=keras.losses.mean_absolute_error, optimizer=keras.optimizers.Adam(learning_rate=lr))\n",
    "    \n",
    "    # load weights\n",
    "    if load_weights:\n",
    "        W_old = mu.dummy_loader(model_name_load)\n",
    "        model.set_weights(W_old)\n",
    "        \n",
    "    # ----------------------------------------------- #\n",
    "    # Major training loop + training batch generation\n",
    "    \n",
    "    batch_GEFS = np.empty((batch_size, N_leads+pad_timelag,)+latent_size)\n",
    "    batch_GEFS[...] = np.nan\n",
    "    batch_CCPA = np.empty((batch_size, N_leads+pad_timelag,)+latent_size)\n",
    "    batch_CCPA[...] = np.nan\n",
    "\n",
    "    batch_GEFS_aug = np.empty((batch_size, N_leads,)+latent_size)\n",
    "    batch_GEFS_aug[...] = np.nan\n",
    "    batch_CCPA_aug = np.empty((batch_size, N_leads,)+latent_size)\n",
    "    batch_CCPA_aug[...] = np.nan\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        print('epoch = {}'.format(i))\n",
    "        if i == 0:\n",
    "            Y_pred = model.predict(valid_GEFS)\n",
    "            record = du.mean_absolute_error(valid_CCPA, Y_pred)\n",
    "            print('Initial validation loss: {}'.format(record))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for j in range(N_batch):\n",
    "            \n",
    "            inds_rnd = du.shuffle_ind(L_train)\n",
    "            inds_ = inds_rnd[:batch_size]\n",
    "            \n",
    "            for k, ind in enumerate(inds_):\n",
    "                # import batch data\n",
    "                name_ = filename_train[ind]\n",
    "                temp_data = np.load(name_, allow_pickle=True)[()]\n",
    "                batch_GEFS[k, ...] = temp_data['GEFS_embed'][:N_leads+pad_timelag, ...]\n",
    "                batch_CCPA[k, ...] = temp_data['CCPA_embed'][:N_leads+pad_timelag, ...]\n",
    "                \n",
    "            if aug_timelag:\n",
    "                for k in range(batch_size):\n",
    "                    i_start = np.random.randint(0, pad_timelag)\n",
    "                    batch_GEFS_aug[k, ...] = batch_GEFS[k, i_start:i_start+N_leads, ...]\n",
    "                    batch_CCPA_aug[k, ...] = batch_CCPA[k, i_start:i_start+N_leads, ...]\n",
    "                    \n",
    "            if aug_revert:\n",
    "                for k in range(batch_size):\n",
    "                    i_revert = np.random.randint(0, 4)\n",
    "                    if i_revert == 4:\n",
    "                        batch_GEFS_aug[k, ...] = batch_GEFS_aug[k, ::-1, ...]\n",
    "                        batch_CCPA_aug[k, ...] = batch_CCPA_aug[k, ::-1, ...]\n",
    "\n",
    "            if (aug_timelag is False) and (aug_revert is False):\n",
    "                batch_GEFS_aug = batch_GEFS[:, :-pad_timelag, ...]\n",
    "                batch_CCPA_aug = batch_CCPA[:, :-pad_timelag, ...]\n",
    "                \n",
    "            model.train_on_batch(batch_GEFS_aug, batch_CCPA_aug)\n",
    "            \n",
    "        # on epoch-end\n",
    "        Y_pred = model.predict(valid_GEFS)\n",
    "        record_temp = du.mean_absolute_error(valid_CCPA, Y_pred)\n",
    "    \n",
    "        if record - record_temp > min_del:\n",
    "            print('Validation loss improved from {} to {}'.format(record, record_temp))\n",
    "            record = record_temp\n",
    "            print(\"Save to {}\".format(model_name_save))\n",
    "            #model.save(model_name_save)\n",
    "            \n",
    "        else:\n",
    "            print('Validation loss {} NOT improved'.format(record_temp))\n",
    "        \n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        # mannual callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4484f-e581-4609-bd56-3b2585c0d230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0787d8f1-056e-4d80-9f3f-2ee719ab365d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
